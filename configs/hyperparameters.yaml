# Train arguments
max_epochs: 500
batch_size: 64
accumulate_grad_batches: 1
learning_rate: 0.0002
weight_decay: 0.01
grad_norm_clip: 5.0
eta_min: 1.0E-5
normalize_features: False

# Data arguments
train_dataset: data/processed/training_diff_tl.h5
val_dataset: data/processed/validation_diff_tl.h5
train_with_tracks_to_predict: False # instead of 128 elements use 8, False is standard WOMD training
num_workers: 16

data_perturb:
  anchor_frame:
    perturb_prob: 0.0
  base_frame: 
    perturb_prob: 0.0
    delta_t: 10.0
    delta_yaw: 0.8
    
model_config:
  decoder:
    input_size: 12   #(x, y, c, s, v, extent, type_ohe)
    output_size: 2  #(accel, yaw_rate)
  dynamics_layer:
    max_acc: 10.0
    max_yaw_rate: 1.0
    delta_t: 0.2
  tl_encoder:
    use_tl_encoder: False
    input_size: 11
    

# Loss options
loss_tracks_to_predict_mask: True  # True is standard WOMD
loss_use_ego_vehicle_mask: False  # False is standard WOMD

# Model arguments
hidden_size: 128
